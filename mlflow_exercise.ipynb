{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track an Experiment with MLflow\n",
    "\n",
    "In this exercise, you will go through the process of training a machine learning model and apply MLOps principles to manage and monitor your machine learning pipeline.\n",
    "\n",
    "Since you have already trained initial models (Logistic Regression and Random Forest) in a previous exercise, you will track these experiments using MLflow to monitor model performance over multiple runs.\n",
    "\n",
    "You will need:\n",
    "- `MLflow` installed (`pip install mlflow`).\n",
    "\n",
    "### Objective\n",
    "\n",
    "By the end of this exercise, you will be able to set up MLflow for experiment tracking, logging model metrics, comparing multiple runs, and deploying a model using MLflow's capabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Set Up MLflow and Required Libraries\n",
    "\n",
    "**Task:** Import the necessary libraries for MLflow and scikit-learn.\n",
    "\n",
    "- Import libraries such as `mlflow`, `mlflow.sklearn`, `pandas`, and others you think are necessary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import mlflow\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import mlflow.sklearn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create and Track an Experiment with MLflow\n",
    "\n",
    "**Task:** Define a new experiment in MLflow.\n",
    "\n",
    "- What command should you use to set up a new experiment in MLflow?\n",
    "- Set up an experiment with the name \"Wearable_Device_Stress_Classifier\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '812917144860531717'. Detailed error Yaml file '/Users/nedday/Documents/All Projects /Processus data/mlruns/812917144860531717/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nedday/Documents/All Projects /Processus data/tp1/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"/Users/nedday/Documents/All Projects /Processus data/tp1/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/Users/nedday/Documents/All Projects /Processus data/tp1/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/Users/nedday/Documents/All Projects /Processus data/tp1/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/Users/nedday/Documents/All Projects /Processus data/tp1/lib/python3.9/site-packages/mlflow/utils/file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file '/Users/nedday/Documents/All Projects /Processus data/mlruns/812917144860531717/meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '812917144860531717'. Detailed error Yaml file '/Users/nedday/Documents/All Projects /Processus data/mlruns/812917144860531717/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nedday/Documents/All Projects /Processus data/tp1/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"/Users/nedday/Documents/All Projects /Processus data/tp1/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/Users/nedday/Documents/All Projects /Processus data/tp1/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/Users/nedday/Documents/All Projects /Processus data/tp1/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/Users/nedday/Documents/All Projects /Processus data/tp1/lib/python3.9/site-packages/mlflow/utils/file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file '/Users/nedday/Documents/All Projects /Processus data/mlruns/812917144860531717/meta.yaml' does not exist.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/nedday/Documents/All%20Projects%20/Processus%20data/mlruns/377287037009484942', creation_time=1731073639311, experiment_id='377287037009484942', last_update_time=1731073639311, lifecycle_stage='active', name='Wearable_Device_Stress_Classifier_experiment', tags={}>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Wearable_Device_Stress_Classifier_experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Track training metrics and log model parameters.\n",
    "\n",
    "- How would you start an MLflow run to log your experiment details?\n",
    "- Train a Logistic Regression model and track its metrics (e.g., accuracy, precision, recall, F1 score) using MLflow.\n",
    "- Log the model using `mlflow.sklearn.log_model()`.\n",
    "\n",
    "**Hint:** You should use `with mlflow.start_run():` to start an MLflow run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6da6fc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/device.csv\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "label_encoder = LabelEncoder()\n",
    "data['Stressed State'] = label_encoder.fit_transform(data['Stressed State'])\n",
    "data['Activity Type'] = label_encoder.fit_transform(data['Activity Type'])\n",
    "\n",
    "X = data.drop('Stressed State', axis=1)\n",
    "y = data['Stressed State']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '812917144860531717'. Detailed error Yaml file '/Users/nedday/Documents/All Projects /Processus data/mlruns/812917144860531717/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nedday/Documents/All Projects /Processus data/tp1/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"/Users/nedday/Documents/All Projects /Processus data/tp1/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/Users/nedday/Documents/All Projects /Processus data/tp1/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/Users/nedday/Documents/All Projects /Processus data/tp1/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/Users/nedday/Documents/All Projects /Processus data/tp1/lib/python3.9/site-packages/mlflow/utils/file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file '/Users/nedday/Documents/All Projects /Processus data/mlruns/812917144860531717/meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '812917144860531717'. Detailed error Yaml file '/Users/nedday/Documents/All Projects /Processus data/mlruns/812917144860531717/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nedday/Documents/All Projects /Processus data/tp1/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"/Users/nedday/Documents/All Projects /Processus data/tp1/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/Users/nedday/Documents/All Projects /Processus data/tp1/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/Users/nedday/Documents/All Projects /Processus data/tp1/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/Users/nedday/Documents/All Projects /Processus data/tp1/lib/python3.9/site-packages/mlflow/utils/file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file '/Users/nedday/Documents/All Projects /Processus data/mlruns/812917144860531717/meta.yaml' does not exist.\n",
      "2024/11/09 12:11:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and metrics logged to MLflow.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# Set up the MLflow experiment\n",
    "mlflow.set_experiment(\"Wearable_Device_Stress_Classifier_experiment\")\n",
    "\n",
    "\n",
    "\n",
    "# Start the MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Initialize the model\n",
    "    model = LogisticRegression(C=0.01,solver='lbfgs',max_iter=1000)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Log model parameters\n",
    "    mlflow.log_params({\n",
    "                      'C': 0.05,\n",
    "                      'solver':'lbfgs',\n",
    "                      'max_iter': 1000\n",
    "                     })\n",
    "\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    \n",
    "    # Log model parameters\n",
    "    mlflow.log_param(\"model_type\", \"LogisticRegression\")\n",
    "    mlflow.log_param(\"max_iter\", model.max_iter)\n",
    "    mlflow.log_param(\"random_state\", model.random_state)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    \n",
    "    # Log the trained model\n",
    "    mlflow.sklearn.log_model(model, \"logistic_regression_model\")\n",
    "    \n",
    "    print(\"Model and metrics logged to MLflow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Compare Multiple Runs\n",
    "\n",
    "- **Task:** Modify the model parameters (e.g., change solver type or regularization strength) and re-run the experiment log.\n",
    "- **Open the MLflow UI:** Start the MLflow UI by running:\n",
    "  ```bash\n",
    "  mlflow ui\n",
    "  ```\n",
    "- Navigate to `http://127.0.0.1:5000` to compare different experiment runs visually. Observe how changing parameters affects the metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-08 12:20:38 +0100] [35921] [INFO] Starting gunicorn 23.0.0\n",
      "[2024-11-08 12:20:38 +0100] [35921] [INFO] Listening at: http://127.0.0.1:5000 (35921)\n",
      "[2024-11-08 12:20:38 +0100] [35921] [INFO] Using worker: sync\n",
      "[2024-11-08 12:20:38 +0100] [35922] [INFO] Booting worker with pid: 35922\n",
      "[2024-11-08 12:20:38 +0100] [35923] [INFO] Booting worker with pid: 35923\n",
      "[2024-11-08 12:20:38 +0100] [35924] [INFO] Booting worker with pid: 35924\n",
      "[2024-11-08 12:20:38 +0100] [35925] [INFO] Booting worker with pid: 35925\n",
      "^C\n",
      "[2024-11-08 12:21:42 +0100] [35921] [INFO] Handling signal: int\n",
      "[2024-11-08 12:21:42 +0100] [35923] [INFO] Worker exiting (pid: 35923)\n",
      "[2024-11-08 12:21:42 +0100] [35922] [INFO] Worker exiting (pid: 35922)\n",
      "[2024-11-08 12:21:42 +0100] [35925] [INFO] Worker exiting (pid: 35925)\n",
      "[2024-11-08 12:21:42 +0100] [35924] [INFO] Worker exiting (pid: 35924)\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Log additional artifacts\n",
    "\n",
    "**Task:** Log a confusion matrix as an artifact in MLflow.\n",
    "\n",
    "- How would you log a confusion matrix plot to MLflow?\n",
    "- Plot a confusion matrix for your predictions and log it as an artifact.\n",
    "\n",
    "**Hint:** Use `seaborn` for plotting and `mlflow.log_artifact()` for logging the plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix plot has been logged as an artifact.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Predicted Negative', 'Predicted Positive'],\n",
    "            yticklabels=['True Negative', 'True Positive'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Save the plot as a file to log it\n",
    "plot_filename = \"confusion_matrix.png\"\n",
    "plt.savefig(plot_filename)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n",
    "mlflow.log_artifact(plot_filename)\n",
    "print(\"Confusion matrix plot has been logged as an artifact.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Model packaging with MLflow\n",
    "\n",
    "**Task:** Register the trained model in the MLflow Model Registry.\n",
    "\n",
    "- How can you register the best model for versioning and potential deployment?\n",
    "- Use the `mlflow.register_model()` function to add your model to the registry.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/09 12:11:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle enregistré dans le registre MLflow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'Wearable_Device_Stress_Classifier_Model' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'Wearable_Device_Stress_Classifier_Model'.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "\n",
    "\n",
    "# Initialiser et entraîner le modèle\n",
    "model = LogisticRegression(C=0.01, solver='lbfgs', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Loguer le modèle\n",
    "mlflow.sklearn.log_model(model, \"logistic_regression_model\")\n",
    "\n",
    "# URI du modèle loggé dans le run\n",
    "model_uri = f\"runs:/{mlflow.active_run().info.run_id}/logistic_regression_model\"\n",
    "\n",
    "# Enregistrer le modèle dans le MLflow Model Registry\n",
    "mlflow.register_model(model_uri, \"Wearable_Device_Stress_Classifier_Model\")\n",
    "\n",
    "print(\"Modèle enregistré dans le registre MLflow.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Deploy the model as a REST API\n",
    "\n",
    "**Task:** Deploy the registered model as a REST API using MLflow.\n",
    "\n",
    "- How would you serve the model locally?\n",
    "- Use `mlflow models serve` to start a local REST API.\n",
    "\n",
    "```bash\n",
    "mlflow models serve -m \"models:/WearableStressClassifierModel/1\" -p 1234\n",
    "```\n",
    "\n",
    "**Task:** Make a prediction request to your model's REST API.\n",
    "\n",
    "- Use Python's `requests` library to send a JSON request to the REST API and get predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédiction : {'predictions': [1]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample = X_test.iloc[:1]  # Choix de la première ligne comme exemple\n",
    "input_data = {\n",
    "    \"dataframe_split\": {\n",
    "        \"columns\": list(sample.columns),\n",
    "        \"data\": sample.values.tolist()\n",
    "    }\n",
    "}\n",
    "\n",
    "# URL de l'API REST\n",
    "url = \"http://127.0.0.1:1234/invocations\"\n",
    "\n",
    "# Envoi de la requête POST\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "response = requests.post(url, headers=headers, data=json.dumps(input_data))\n",
    "\n",
    "# Affichage du résultat de la prédiction\n",
    "if response.status_code == 200:\n",
    "    prediction = response.json()\n",
    "    print(\"Prédiction :\", prediction)\n",
    "else:\n",
    "    print(\"Erreur :\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Manage model versions\n",
    "\n",
    "**Task:** Explore the MLflow Model Registry.\n",
    "\n",
    "- How can you manage different versions of your model in MLflow?\n",
    "- Experiment with updating the registered model after retraining with different hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nom du modèle : Wearable_Device_Stress_Classifier_Model\n",
      "  Version : 2 | Stade : None | Statut : READY\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Créer un client MLflow\n",
    "client = MlflowClient()\n",
    "\n",
    "# Liste des modèles enregistrés\n",
    "models = client.search_registered_models()\n",
    "for model in models:\n",
    "    print(f\"Nom du modèle : {model.name}\")\n",
    "    for version in model.latest_versions:\n",
    "        print(f\"  Version : {version.version} | Stade : {version.current_stage} | Statut : {version.status}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5db46e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version : 2 | Stade : None | Statut : READY\n",
      "Version : 1 | Stade : None | Statut : READY\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Wearable_Device_Stress_Classifier_Model\"  \n",
    "model_versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "\n",
    "for version in model_versions:\n",
    "    print(f\"Version : {version.version} | Stade : {version.current_stage} | Statut : {version.status}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Automated workflow\n",
    "\n",
    "**Task:** Use MLflow Projects to automate the workflow.\n",
    "\n",
    "- Create an `MLproject` file to define the script and dependencies in a reproducible manner.\n",
    "- Run the project locally to validate your setup.\n",
    "\n",
    "```bash\n",
    "mlflow run .\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Visualize metrics and monitor models\n",
    "\n",
    "**Task:** Visualize metrics using the MLflow UI.\n",
    "\n",
    "- How can you use the MLflow UI to compare runs and visualize metrics like `accuracy`, `precision`, `recall`, and `f1_score`?\n",
    "- Set up custom monitoring dashboards using Grafana if needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary and exploration\n",
    "\n",
    "- **Key Questions:**\n",
    "  1. How did changing model parameters impact performance metrics like accuracy, precision, and recall?\n",
    "  2. What are the benefits of tracking multiple runs using MLflow?\n",
    "  3. How can artifact logging be useful for diagnosing model behavior?\n",
    "  4. What are the challenges in deploying machine learning models, and how does MLflow assist?\n",
    "  5. How can visualizing metrics help you understand your model's performance over time?\n",
    "  6. Why is monitoring model drift important, and how can MLflow help?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
